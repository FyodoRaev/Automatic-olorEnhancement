Часто бывает что цвета на тайловых моделях / ортофотопланах слишком тусклые, из-за чего результат выглядит менее выигрышно 

Было бы хорошо иметь инструмент цветокоррекции, который бы исправлял такие проблемы. Желательно, чтобы он работал с уже посроенной текстурой/ортофотопланом (чтобы не приходилось его перестраивать посоле применения инструмента).

Основной скрипт для инференса - guidedEnchacement.py

### Концептуальный план

1. **Входные данные**:
    
    - `A`: Оригинальное изображение высокого разрешения (например, 20 Мп).
    - Модель DPED, которая принимает на вход изображение низкого разрешения.
2. **Процесс**:
    
    1. Загружаем `A`.
    2. Создаем `a` — уменьшенную копию `A`, подходящую для модели DPED.
    3. Подаем `a` в модель DPED и получаем `b` — улучшенную версию низкого разрешения.
    4. **Ключевой шаг: работа с "дельтой" (Δ)**.
        - Чтобы избежать цветовых артефактов, лучше работать не в RGB, а в цветовом пространстве, разделяющем яркость и цвет (например, CIE LAB или YCrCb). Это позволяет применить структурные улучшения (яркость) отдельно от цветовых. Возьмем **CIE LAB**, так как оно перцепционно более однородно.
        - Конвертируем `A`, `a` и `b` в LAB.
        - Вычисляем дельту улучшения `Δ` для каждого канала: `Δ_L = L_b - L_a`, `Δ_C1 = a_b - a_a`, `Δ_C2 = b_b - b_a`.
    5. **Guided Upsampling**:
        - Используем Guided Filter для апскейлинга дельт.
	        - Внутри ТРИ основных штуки:
				1. Локальная линейная модель: В каждом окне фильтрации выходное значение Q выражается как линейная функция от guidance G:  
				   Q_i = a_k · G_i + b_k .  
				2. Сохранение границ: Градиент выходного изображения пропорционален градиенту guidance: ∇Q ≈ a · ∇G, что предотвращает размытие контуров .  
				3. Регуляризация: Параметр ε в уравнении коэффициентов a_k = Cov(G, I) / (Var(G) + ε) контролирует степень сглаживания 
        - **Гайд (Guidance image)**: Яркостный канал `L_A` из полноразмерного оригинала. Он содержит всю информацию о границах и структурах высокого разрешения.
        - **Вход (Input image)**: Низкоразмерные дельты `Δ_L`, `Δ_C1`, `Δ_C2`. Их нужно сначала апскейлить до размера `A` простым методом (например, `bicubic`), а затем уже фильтровать.
        - Применяем Guided Filter:
            - `Δ_L_high = guidedFilter(guide=L_A, src=upscaled(Δ_L))`
            - `Δ_C1_high = guidedFilter(guide=L_A, src=upscaled(Δ_C1))`
            - `Δ_C2_high = guidedFilter(guide=L_A, src=upscaled(Δ_C2))`
    7. **Сборка финального изображения**:
        - Применяем полноразмерные дельты к полноразмерному оригиналу `A` в пространстве LAB:
            - `L_B = L_A + Δ_L_high`
            - `a_B = a_A + Δ_C1_high`
            - `b_B = b_A + Δ_C2_high`
        - Собираем каналы `L_B`, `a_B`, `b_B` и конвертируем обратно в RGB. Это и будет наше итоговое изображение `B`.


